

# Package structure and distribution


The previous chapter provided a practical overview of how to create, install, and distribute (if desired) a Python package. This chapter now goes into more detail about what a Python package actually is, digging deeper into how packages are structured, installed, and distributed. We begin with a discussion of what modules and packages are in Python and how they are imported and used in a Python program. We then discuss some more advanced package structure topics such as controlling the import behavior of a package and including non-code files, like data. The chapter finishes with a discussion of package distributions and how they are installed. Along the way, we'll demonstrate key concepts by continuing to develop our `pycounts` package from the previous chapter.

## Packaging fundamentals

We'll begin this chapter by exploring some of the lower-level implementation details related to what packages are, how they're structured, and how they're used in Python. 

All data in a Python program is represented by objects or by relations between objects. For example, integers and functions are kinds of Python objects. We can find the type of a Python object using the `type()` function. For example, the code below, run in an Python interpreter, creates an integer object and a function object mapped to the names `a` and `hello_world` respectively:

```python
>>> a = 1
>>> type(a)
```

```console
int
```

```python
>>> def hello_world(name):
        print(f"Hello world! My name is {name}.")
>>> type(hello_world)
```

```console
function
```

The Python object important to our discussion of packages is the "module" object. A module is an object that serves as an organizational unit of Python code. In the simplest case, this Python code is stored in a file with a *.py* suffix and is imported using the `import` statement, which creates a module object with the same name as the imported file (excluding the *.py* suffix). For example, imagine we have a module *`greetings.py`* in our current directory containing functions to print "Hello World!" in English and Squamish (the [Squamish people](https://en.wikipedia.org/wiki/Squamish_people) are an indigenous people of modern-day British Columbia, Canada):

```python
def hello_world():
    print("Hello World!")

def hello_world_squamish():
    print("I chen tl'iḵ!")
```

We can import that module using the `import` statement and can use the `type()` function to verify that we created a module object which has been mapped to the name "greetings" (the name of the file):

```python
>>> import greetings
>>> type(greetings)
```

```python
module
```

As mentioned earlier, this module object is an organizational unit of code. We say this because the content of the module (in this case, the two "hello world" functions) are accessed via the module name and "dot notation". For example:

```python
>>> greetings.hello_world()
```

```python
"Hello World!"
```

```python
>>> greetings.hello_world_squamish()
```

```python
"I chen tl'iḵ!"
```

At this point in our discussion, it's useful to mention Python's namespaces. A "namespace" in Python is a mapping from names to objects. From the code examples above, we've added the names `a` (an integer), `hello_world` (a function), and `greetings` (a module) to the current namespace and can use those names to refer to the objects we created. The `dir()` function can be used to inspect a namespace. When called with no arguments, `dir()` returns a list of names defined in the current namespace:

```python
>>> dir()
```

```python
['__annotations__', '__builtins__', '__doc__', '__loader__',
 '__name__', '__package__', '__spec__', 'a', 'hello_world',
 'greetings']
```

In the output above, we can see the names of the three objects we have defined in this section: `a`, `hello_world`, and `greetings`. The other names prefixed with double underscores are objects that were initialized automatically when we started the Python interpreter and are implementation details that aren't important to our discussion here, but can be read about in the Python [documentation](https://docs.python.org/3/reference/executionmodel.html?highlight=__builtins__#execution-model).

Namespaces are created at different moments, have different lifetimes, and can be accessed from different parts of a Python program - but these details digress from the text and we point interested readers to the Python [documentation](https://docs.python.org/3/tutorial/classes.html#python-scopes-and-namespaces) to learn more. The important point to make here is that, when a module is imported using the `import` statement, a module object is created and it has its own namespace populated by the Python code (i.e, definitions and statements) within that module. A module's namespace can be accessed using the module's name and dot notation, as we saw earlier with our `greetings` module. In this way, the module object isolates a collection of code and provides us with a clean, logical, and organized way to access it.

We can view the namespace of a module by passing the module object as an input to the `dir()` function :

```python
>>> dir(greetings)
```

```python
['__annotations__', '__builtins__', '__doc__', '__loader__',
 '__name__', '__package__', '__spec__', 'hello_world',
 'hello_world_squamish']
```

An important point to stress here is that namespaces not only help us organize code, but they help us avoid name collisions because there is no relation between names in different namespaces. That is, we can have multiple variables of the exact same name in a Python session if they exist in different namespaces.

For example, in the Python session we've been running in this section we have access to two `hello_world` functions; one that was defined earlier in our interactive interpreter, and one defined in the `greetings` module. While these functions have the exact same name, there is no relation between them because they exist in different namespaces; `greetings.hello_world()` exists in the `greetings` module namespace and `hello_world()` exists in the top-level global namespace. So, we can access both with the appropriate syntax:

```python
>>> hello_world("Tom")
```

```python
"Hello world! My name is Tom."
```

```python
>>> greetings.hello_world()
```

```python
"Hello World!"
```

<!-- #region -->
Now that we have a basic understanding of modules, we can further discuss packages. Packages are just a collection of one or more modules. Put simply, they provide another level of abstraction for our code and allow us to group and organize related modules (as well as non-code files, like data, as we'll discuss in **{numref}`04:Including-data-in-a-package`**) under a single package namespace. 

Loosely speaking, a package is like a module containing other modules. In fact, this is pretty much how Python treats packages. Regardless of whether you `import` a single, standalone module (i.e., a *.py* file) or a package (i.e., a directory), Python will create a module object in the current namespace. For example, let's import the `pycounts` package we created in **Chapter 3: [How to package a Python]** and check its type:

>If you're following on from **Chapter 3: [How to package a Python]** and created a virtual environment for your `pycounts` package using `conda`, as we did in **{numref}`03:Create-a-virtual-environment`**, be sure to activate that environment before continuing with this chapter by running `conda activate pycounts` at the command line.

<!-- #endregion -->

```python
>>> import pycounts
>>> type(pycounts)
```

```python
module
```

Note that despite importing our `pycounts` package (a collection of modules), Python still created a single module object. Just as before, we can access the contents of our package via dot notation. For example, we can import the `count_words()` function from the `pycounts` module of the `pycounts` package using the following syntax:

```python
>>> from pycounts.pycounts import count_words
>>> type(count_words)
```

```python
function
```

<!-- #region -->
While we get a module object regardless of whether we import a single module (a single *.py* file) or a package (a directory containing one or more *.py* files), one technical difference between a module and a package in Python is that packages are imported as module objects that have a `__path__` attribute. When importing a package or module, Python searches for it in the default list of directories defined in `sys.path`:

```python
>>> import sys
>>> sys.path
```

```python
['',
 '/opt/miniconda/base/envs/pycounts/lib/python39.zip',
 '/opt/miniconda/base/envs/pycounts/lib/python3.9',
 '/opt/miniconda/base/envs/pycounts/lib/python3.9/lib-dynload',
 '/opt/miniconda/base/envs/pycounts/lib/python3.9/site-packages']
```

>The list of directories shown by `sys.path` will change depending on how you installed Python and whether or not you're in a virtual environment. The empty string at the start of the list represents the current directory.

But when importing something from a package, Python uses the `__path__` attribute of the package to look for that something, rather than the paths in `sys.path`. For example, let's check that the `pycounts` module object we just created does indeed have an attribute called `__path__`, but the `greetings` module object we created from *`greetings.py`* earlier does not:
<!-- #endregion -->

```python
>>> pycounts.__path__
```

```python
['/Users/tomasbeuzen/pycounts/src/pycounts']
```

```python
>>> greetings.__path__
```

```python
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
AttributeError: module 'greetings' has no attribute '__path__'
```

`>Recall that `poetry` installs packages in "editable" mode when you use `poetry install`, such that a link to the package's location is installed, rather than an independent distribution of the package itself. That's why we see the absolute path to our package source code above when running `pycounts.__path__`.
>
>If you have installed `pycounts` from a local sdist or wheel, or from PyPI, you would see a different path. Most likely including a *site-packages/`* directory, which is where Python puts installed packages, e.g.:
>
>console
['/opt/miniconda/base/envs/pycounts/lib/python3.9/site-packages/pycounts']
```

We'll talk more about package installation in **{numref}**`04:Package-distribution-and-installation`.
````

What this all means is that when you type `import pycounts.plotting`, Python first searches for a module or package called `pycounts` in the list of search paths defined by `sys.path`. If `pycounts` is a package, it then searches for `plotting` using `pycounts.__path__` as the search path (rather than `sys.path`). At this point, we're straying into the nuances of Python's import system and digressing from the scope of this book, but you can read more about Python's fascinating import system in the Python [documentation](https://docs.python.org/3/reference/import.html) if you're interested.

Ultimately, the important takeaway message from this section is that packages are a collection of Python modules. They help us better organize and access our code, as well as distribute it to others, as we'll discuss in **{numref}`04:Package-distribution-and-installation`**.

## Package structure

With the theory out of the way, we'll now get back to a more practical focus in this section. We'll discuss how packages are structured, how we can control their `import` behaviour, and how we can include non-code files, like data, into our packages.

### Package contents

<!-- #region -->
As we discussed in **{numref}`04:Packaging-fundamentals`**, packages are a way of organizing and accessing a collection of modules. Fundamentally, a package is identified as a directory containing an *`__init__.py`* file, and a module is a file with a *.py* extension that contains Python code. Below is an example directory structure of a simple Python package with two modules and a subpackage:

```
pkg
├── __init__.py
├── module1.py
└── subpkg
    ├── __init__.py
    └── module2.py
```

The *`__init__.py`* tells Python to treat a directory as a package (or subpackage). It is common for *`__init__.py`* files to be empty, but they can also contain helpful initialization code to run when your package is imported, as we'll discuss in **{numref}`04:The-__init__.py-file`**.

The above structure satisfies the criteria for a Python package, and you would be able to `import` content from this package on your local computer if it was in the current working directory (or if its path had been added to `sys.path`). But this package lacks the content required to make it installable so that it can be used across different projects. 

To create such a package, we first need a tool capable of installing and building packages. Currently the most common tools used for package development are `poetry`, `flit`, and `setuptools`. In this book, we use `poetry` but we'll compare these tools later in **{numref}`04:Packaging-tools`**. Regardless of the tool you use, it will rely on a configuration file(s) to manage the metadata, installation, maintenance, and distribution of your package. In a `poetry`-managed project that file is the *`pyproject.toml`*. It's also good practice to include a README in your package's root directory to provide high-level information about the package, and to put the Python code of your package in a *`src/`* directory (we'll discuss why this is in **{numref}`04:The-source-layout`**). Thus, the structure for an installable package looks more like this:

```
pkg
├── src
│   └── pkg
│       ├── __init__.py
│       ├── module1.py
│       └── subpkg
│           ├── __init__.py
│           └── module2.py
├── README.md
└── pyproject.toml
```

The above structure is suitable for a simple package, or one intended solely for personal use. But most packages include many more bells and whistles than this, such as detailed documentation, tests that can be run to validate the functionality of the package, and more. The `pycounts` package we created in **{numref}`03:Creating-a-package-structure`** is a more typical example of a Python package structure:

```
pycounts
├── .readthedocs.yml
├── CHANGELOG.md
├── CONDUCT.md
├── CONTRIBUTING.md
├── docs
│   ├── changelog.md
│   ├── conduct.md
│   ├── conf.py
│   ├── contributing.md
│   ├── example.ipynb
│   ├── index.md
│   ├── make.bat
│   ├── Makefile
│   └── requirements.txt
├── LICENSE
├── README.md
├── poetry.lock
├── pyproject.toml
├── src
│   └── pycounts
│       ├── __init__.py
│       ├── plotting.py
│       └── pycounts.py
└── tests
    ├── einstein.txt
    └── test_pycounts.py
```

Not all of this content will be included in the version of your package that you install or distribute to others. Typically, it's just the Python code (in the *`src/`* directory) that forms the installable version of your package (but we'll show how you can specify additional content to include in **{numref}`04:Including-non-code-files-in-a-package`**). The rest of the content, like documentation and tests, exist to support development and this content is not needed by the users of your package. Instead, it's usually shared via a collaborative medium like GitHub, so that developers can access and contribute to it.

>The package structure described in this section is technically called a "regular package" in Python and it is what the vast majority of Python packages and developers use.
>
>However, Python also supports a second type of package known as a "namespace package". Namespace packages are a way of splitting a single Python package across multiple directories. Unlike regular packages, where all contents live in the same directory hierarchy, namespace packages can be formed from directories in different locations on a file system and do not contain an *`__init__.py`* file.
>
>The main reason a developer might want to use a namespace package is if they wish to develop, install, and distribute portions of a package separately, or if they want to combine packages that reside on different locations on their file system. Namespace packages can be a confusing topic for beginners and the vast majority of users will never create a namespace package so we won't discuss them further in this book. Instead we refer readers interested in learning more about them to [PEP 420](https://www.python.org/dev/peps/pep-0420/) and the Python [documentation](https://docs.python.org/3/reference/import.html#namespace-packages). As a result, when we use the term "package" in this book, we specifically mean "regular package".

<!-- #endregion -->

### Package and modules names

When building a package, it's important to select appropriate names for your package and its modules. Python package naming guidelines and conventions are described in [Python Enhancement Proposal (PEP) 8 - Style Guide for Python Code](https://www.python.org/dev/peps/pep-0008/) and [PEP 423 - Naming conventions and recipes related to packaging](https://www.python.org/dev/peps/pep-0423/). The fundamental guidelines are that:
- Packages and modules should have a single, short, all-lowercase name; and,
- Underscores can be used to separate words in a name if it improves readability, but their use is typically discouraged.

In terms of the actual name chosen for a module or package, it may be helpful to consider the following "three M's":
1. **Meaningful**: the name should somewhat reflect the functionality of the package.
2. **Memorable**: the name should be easy for users to find, remember, and relate to other relevant packages.
3. **Manageable**: remember that users of your package will access its contents/namespace via dot notation. Make it as quick and easy as possible for them to do this by keeping your names short and sweet. For example, imagine if we called our `pycounts` package something like `count_words_in_file`. Every time a user wanted to access the `count_words()` function from the `pycounts` module, they'd have to write this: `from count_words_in_file.pycounts import count_words()` - yikes!

Finally, you should also check [PyPI](https://pypi.org) and other popular hosting sites like GitHub, GitLab, BitBucket, etc., to make sure your chosen name is not already in use.

```{r 04-pkg-naming, fig.cap = "Keep package names meaningful, memorable, and manageable.", out.width = "50%", fig.retina = 2, fig.align = "center", echo = FALSE, message = FALSE, warning = FALSE}
knitr::include_graphics("../images/04-pkg-naming.png")
```

### Intra-package references

<!-- #region -->
When building packages of multiple modules, it is common to want to use code from one module in another. For example, consider the following package structure:

```
src
└── package
    ├── __init__.py
    ├── moduleA.py
    ├── moduleB.py
    └── subpackage
        ├── __init__.py
        └── moduleC.py
```

A developer may want to import code from `moduleA` in `moduleB`. This is an "intra-package reference" and can be accomplished via an "absolute" or "relative" import.

Absolute imports use the package name in an absolute context. Relative imports use dots to indicate from where the relative import should begin. A single dot indicates an import relative to the current package (or subpackage), additional dots can be used to move further up the packaging hierarchy, one level per dot after the first dot.

{numref}`intra-package-table` shows some practical examples of absolute and relative imports, based on the package structure shown previously.

```{table} Demonstration of absolute and relative intra-package imports.
:name: intra-package-table

| | Absolute | Relative |
| :--- | :--- | :--- |
|Import from `moduleA` in `moduleB`| `from package.moduleA import XXX` | `from .moduleA import XXX`
|Import from `moduleA` in `moduleC`| `from package.moduleA import XXX` |`from ..moduleA import XXX`|
|Import from `moduleC` in `moduleA`| `from package.subpackage.moduleC import XXX` |`from .subpackage.moduleC import XXX`|
```

While the choice here mostly comes down to personal preference, [PEP 8](https://www.python.org/dev/peps/pep-0008/) recommends using absolute imports because they are explicit.
<!-- #endregion -->

### The \_\_init\_\_.py file

<!-- #region -->
Earlier we discussed how an *`__init__.py`* file is used to tell Python that the directory containing the *`__init__.py`* file is a package. The *`__init__.py`* file can be, and often is, left empty and only used for the purpose of identifying a directory as a package. However, it can also be used to add objects to the package's namespace, provide documentation, and/or run other initialization code.

We'll demonstrate this functinoality by example using the `pycounts` packages we developed in **Chapter 3: [How to package a Python]**. Consider the *`__init__.py`* of our package:

```{code-block}
---
emphasize-lines: 14
---
pycounts
├── .readthedocs.yml
├── CHANGELOG.md
├── CONDUCT.md
├── CONTRIBUTING.md
├── docs
│   └── ...
├── LICENSE
├── poetry.lock
├── pyproject.toml
├── README.md
├── src
│   └── pycounts
│       ├── __init__.py
│       ├── plotting.py
│       └── pycounts.py
└── tests
    └── ...
```

When a package is imported, the *`__init__.py`* file is executed, and any objects it defines are bound to the package's namespace. The `py-pkgs-cookiecutter` we used to create our `pycounts` package (**{numref}`03:Creating-a-package-structure`**) already populated our *`__init__.py`* file with a variable called `__version__`:

```python
# read version from installed package
from importlib.metadata import version
__version__ = version("pycounts")
```

In Python packaging, it's convention to define a package's version in the top-level *`__init__.py`* file using the `__version__` attribute. Sometimes you'll see this attribute hard-coded like `__version__ = "0.1.0"` but it's better to have it defined programatically using the `importlib.metadata` which gets a package's version from the installed package metadata. Because any objects defined in the *`__init__.py`* get bound to the package's namespace upon `import`, we should be able to access the `__version__` of our package via its namespace:

```python
>>> import pycounts
>>> pycounts.__version__
```

```console
0.1.0
```

Another common use case of the *`__init__.py`* file is to control the import behavior of a package. For example, there are currently only two main functions that users will commonly use from our `pycounts` package: `pycounts.pycounts.count_words()` and `pycounts.plotting.plot_words()`. Currently, users have to type the full path to these functions to import them:

```python
from pycounts.pycounts import count_words
from pycounts.plotting import plot_words
```

We could make life easier for our users by importing these core functions in `pycounts`'s *`__init__.py`* file which would bind them to the package namespace. For example, the code below added to the *`__init__.py`* file imports our core functions `pycounts.pycounts.count_words()` and `pycounts.plotting.plot_words()`: 
<!-- #endregion -->

```python
# read version from installed package
from importlib.metadata import version
__version__ = version(__name__)

# populate package namespace
from pycounts.pycounts import count_words
from pycounts.plotting import plot_words
```

The functions are now bound to the `pycounts` namespace, so users can access them like this:

```python
>>> import pycounts
>>> pycounts.count_words
```

```console
<function count_words>
```

Ultimately, the *`__init__.py`* file can be used to customize how your package and its contents are imported. It's an interesting exercise to visit large Python packages such as [NumPy](https://github.com/numpy/numpy/blob/main/numpy/__init__.py), [pandas](https://github.com/pandas-dev/pandas/blob/master/pandas/__init__.py), or [scikitlearn](https://github.com/scikit-learn/scikit-learn/blob/main/sklearn/__init__.py) to see the kinds of initialization code they run in their the *`__init__.py`* files.

### Including non-code files in a package

Consider again the structure of our `pycounts` package:

```
pycounts
├── .readthedocs.yml
├── CHANGELOG.md
├── CONDUCT.md
├── CONTRIBUTING.md
├── docs
│   ├── make.bat
│   ├── Makefile
│   ├── requirements.txt
│   ├── changelog.md
│   ├── conduct.md
│   ├── conf.py
│   ├── contributing.md
│   ├── index.md
│   └── usage.ipynb
├── LICENSE
├── README.md
├── poetry.lock
├── pyproject.toml
├── src
│   └── pycounts
│       ├── __init__.py
│       └── pycounts.py
└── tests
    └── test_pycounts.py
```

The installable version of your package that you distribute to others will typically only contain the Python code in the *`src/`* directory. The rest of the content exists to support development of the package and is not needed by users to actually use the package on their machine. This content is typically shared by the developer using a service like GitHub, so that other developers can access and contribute to it if they wish. 

However, it is possible to include arbitrary additional content in your package that will get installed by users, along with the usual Python code. The method of doing this varies depending on what packaging tool you're using, but with `poetry`, you can specify the extra content you wish to include in your package using the `include` parameter under the `[tool.poetry]` table in *`pyproject.toml`*. For example, if we wanted to include our *`tests/`* directory and *`CHANGELOG.md`* file to our installable package distribution, we would add the following to *`pyproject.toml`*:

```{code-block} toml
---
emphasize-lines: 8
---
[tool.poetry]
name = "pycounts"
version = "0.1.0"
description = "Calculate word counts in a text file!"
authors = ["Tomas Beuzen"]
license = "MIT"
readme = "README.md"
include = ["tests/*", "CHANGELOG.md"]

...rest of file hidden...
```

Most developers won't ship additional content with their package like this, preferring to share it via a service like GitHub so it can be accessed by those who need it. But there are certainly use cases for this functionality - for example, if you're sharing a package privately within an organization, you may wish to ship everything with your package (documentation, tests, etc.).

### Including data in a package

<!-- #region -->
One type of non-code file that is commonly included with Python packages is data. There are several reasons why a developer might want to include data in their package:

1. It's required to use some of the package's functionality;
2. To provide example data to help demonstrate the functionality of the package;
3. As a method of distributing and versioning a data file(s); 
4. If the package is being used to bundle up a reproducible data analysis and it's important to keep the code and data together.

Regardless of the use case, there are two typical ways to include data in a Python package:

1. Include the raw data as part of the package, and provide code to help users load it (if required). This option is well-suited to smaller data files, or for data that the package absolutely depends on.
2. Include scripts as part of the package that download the data from an external source. This option is suited to large data files, or ones that a user may only need optionally.

We'll demonstrate option 1 above with an example. Our `pycounts` package helps users calculate words counts in text files. To help demonstrate our package's functionality, it might be helpful to add an example text file to our package for our users to practice with. For our package, we'll add the novel "Flatland", by Edwin Abbott {cite:p}`abbott1884` ([available online](https://www.gutenberg.org/ebooks/97)).

To include this data in our package we need to do two things:

1. Include the raw data file in our package as a *.txt* file; and,
2. Include code to help a user access the data.

We'll start by creating a new *`data`* subpackage in our *`src/pycounts/`* directory where you should download and place the above file as *`flatland.txt`*. We'll also create a new module *`datasets.py`* in our package that we'll shortly populate with code to help users load data. Our `pycounts` directory structure now looks like this:

```{code-block}
---
emphasize-lines: 15-18
---
pycounts
├── .readthedocs.yml
├── CHANGELOG.md
├── CONDUCT.md
├── CONTRIBUTING.md
├── docs
│   └── ...
├── LICENSE
├── poetry.lock
├── pyproject.toml
├── README.md
├── src
│   └── pycounts
│       ├── __init__.py
│       ├── data
│       │   ├── __init__.py
│       │   └── flatland.txt
│       ├── datasets.py
│       ├── plotting.py
│       └── pycounts.py
└── tests
    └── ...
```

Now we need to add some Python code to *`datasets.py`* to help users load the example data. The recommended way to access data files in a package is using the `importlib.resources` [module](https://docs.python.org/3/library/importlib.html#module-importlib.resources). The main function of our `pycounts` package, `pycounts.count_words()` requires users to pass a file path to the text file they want to count words in. So, we need to write a function in our new *`datasets.py`* that returns the path to our "flatland.txt" file. `importlib.resources` has a `path()` function to help us do that. You can read about this function in the Python [documentation](https://docs.python.org/3/library/importlib.html#importlib.resources.path); it is used in a `with` statement and requires two parameters, the location of the subpackage the data is in (`"pycounts.data"`) and the name of the data file (`"flatland.txt"`). The code below, which we'll add to *`datasets.py`*, demonstrates its usage:

```python
from importlib import resources

def get_flatland():
    """Get path to example "Flatland" [1]_ text file.

    Returns
    -------
    pathlib.PosixPath
        Path to file.

    References
    ----------
    .. [1] E. A. Abbott, "Flatland", Seeley & Co., 1884.
    """
    with resources.path("pycounts.data", "flatland.txt") as f:
        data_file_path = f
    return data_file_path
```

Once you've added this code to *`datasets.py`*, you can try it out:

```python
>>> from pycounts.datasets import get_flatland
>>> get_flatland()
```

```console
PosixPath('/Users/tomasbeuzen/pycounts/src/pycounts/data/flatland.txt')
```

A user can directly use this path in the `pycounts` function `count_words()` as follows:

```python
>>> from pycounts.pycounts import count_words
>>> from pycounts.datasets import get_flatland
>>> flatland_path = get_flatland()
>>> count_words(flatland_path)
```

```console
Counter({'the': 2245, 'of': 1597, 'to': 1078, 'and': 1074, 
'a': 902, 'i': 706, 'in': 698, 'that': 486, ... })
```

This is just one example of how we can include data as part of our package and expose it to a user. The `importlib.resources` module can be used to load any kind of data in different ways (as a path, as a string, as a binary file, etc.). If you're developing a package that includes user-facing data, we recommend taking a look at the "datasets" modules included in larger Python libraries such as [scikit-learn](https://github.com/scikit-learn/scikit-learn/tree/main/sklearn/datasets), [torchvision](https://github.com/pytorch/vision/tree/main/torchvision/datasets), or [statsmodels](https://github.com/statsmodels/statsmodels/tree/main/statsmodels/datasets) to learn more.
<!-- #endregion -->

### The source layout

<!-- #region -->
When describing and defining package structure throughout this book, we have been nesting our package's Python code inside a *`src/`* directory, as in this example package structure. This layout is called the "src"/"source" layout for obvious reasons.

```{code-block}
---
emphasize-lines: 2
---
pkg
├── src
│   └── pkg
│       ├── __init__.py
│       ├── module1.py
│       └── subpkg
│           ├── __init__.py
│           └── module2.py
├── README.md
└── pyproject.toml
```

However, nesting a package's code in a *`src/`* directory is not required to build a package, and it's also common to see packages without it. We'll call this the "non-src" layout, and show an example below.

```{code-block}
---
emphasize-lines: 2
---
pkg
├── pkg
│   ├── __init__.py
│   ├── module1.py
│   └── subpkg
│       ├── __init__.py
│       └── module2.py
├── README.md
└── pyproject.toml
```

In general, we recommend using the "src" layout over the "non-src" layout (and so does the [Python Packaging Authority](https://packaging.python.org/tutorials/packaging-projects/)), because it has several advantages when it comes to developing and distributing installable Python packages. We list a few of these below:

1. For developers using a testing framework like `pytest`, a "src" layout forces you to install your package before it can be tested. Most developers would agree that you would want to test your package as it will be installed by users, rather than as it currently exists on your own machine. The problem with a "non-src" layout is that Python can `import` your package even if it is not installed. This is because in most cases the first place Python searches when running `import` is the current directory (check this by importing `sys` and running `sys.path[0]`). Without a "src" folder, Python will find your package as it exists in the current directory and import it. This issue is described in detail in Ionel Cristian Mărieș' [Packaging a Python Library](https://blog.ionelmc.ro/2014/05/25/python-packaging/) and Hynek Schlawack's[Testing and Packaging](https://hynek.me/articles/testing-packaging/) excellent blog posts for those interested.
    
2. A "src" layout leads to cleaner editable installs of your package. Recall from **{numref}`03:Installing-your-package`** that when developing a package, it's common to install it in editable mode (the default when running `poetry install`). This adds the path to your project's Python code to the `sys.path` list so that changes to your source code are immediately available without needing to reinstall.  With a "src" layout that path looks something like this:

    ```console
    '/Users/tomasbeuzen/pycounts/src'
    ```
    
    In contrast, a "non-src" layout will add your project's root to `sys.path` (there is no "src" directory to provide a layer of separation):
    
    ```console
    '/Users/tomasbeuzen/pycounts/'
    ```
    
    There's usually a lot more than just Python code at that path. There could be test modules, scratch code, data files, documentation, etc., all of which are now potentially importable in your development workflow!

3. Finally, "src" is general a universally recognized location for source code, making it easier for others to quickly navigate and find the contents of your package.

Ultimately, while you can certainly use a "non-src layout" to develop a package, using a "src" layout will reduce the chance of things breaking down the line (for example, uploading a broken distribution to PyPI).
<!-- #endregion -->

## Package distribution and installation

In this section, we won't be writing any code, but rather we will discuss concepts related to package distribution and installation for those interested. If that's not you, feel free to skip to **{numref}`04:Version-control`**.

As we saw in **Chapter 3: [How to package a Python]**, the typical workflow for developing and distributing a Python packages is as follows:

1. A *developer* creates a Python package on their machine;
2. The *developer* uses a tool like `poetry` to build a distribution from that package;
3. The *developer* shares the distribution, usually by uploading to a online repository like [PyPI](https://pypi.org); and,
4. A *user* uses an installation tool like `pip` to download and install the distribution on their machine.
5. (Optional) *Users* provide feedback to the developer about the package (identify bugs, request features, etc.) and the cycle repeats.

```{r 04-pkg-cycle, fig.cap = "The Python package cycle.", out.width = "100%", fig.retina = 2, fig.align = "center", echo = FALSE, message = FALSE, warning = FALSE}
knitr::include_graphics("../images/04-pkg-cycle.png")
```

To build up an intuition of the steps in this process, we'll begin at the user-end, and discuss how packages are installed. We'll then work our way backwards to better understand what distributions are and how to make them.

### Package installation

To be installed, a Python package needs to have two directories:
1. A folder of the package's source files (i.e., modules and subpackages) named *`{package}`*.
2. A folder of metadata named *`{package}-{version}.dist-info`*. This folder contains files of information about the package, such as metadata about the package's author and what versions of Python it supports (METADATA), the package's license (LICENSE), what tool installed it (INSTALLER), and more. These files are described in detail in [PEP 427](https://www.python.org/dev/peps/pep-0427/#the-dist-info-directory).

When you install a package with an installer like `pip` the above folders are copied into the *`site-packages`* directory of your Python installation, which is one of the default places Python looks when importing a package. The exact path to the *`site-packages`* folder varies depending on how you installed Python and whether you're currently using a virtual environment. You can check the path using the `sys.path` variable. The below paths are for a MacOS, with Python installed via [Miniconda](https://docs.conda.io/en/latest/miniconda.html), and with a virtual environments called `pycounts` activated:

```python
>>> import sys
>>> sys.path
```

```{code-block language="code-block"}
---
emphasize-lines: 5
---
['',
'/opt/miniconda/base/envs/pycounts/lib/python39.zip',
'/opt/miniconda/base/envs/pycounts/lib/python3.9',
'/opt/miniconda/base/envs/pycounts/lib/python3.9/lib-dynload',
'/opt/miniconda/base/envs/pycounts/lib/python3.9/site-packages']
```

If you navigate to the *`site-packages`* folder you will see examples of the *`{package}`* and *`{package}-{version}.dist-info`* folders for each package you have installed. For example, if we were to `pip install` the `pycounts` package we uploaded to PyPI in **{numref}`03:Building-and-distributing-your-package`**, we would see the following in our *`site-packages`* folder:

```
'/opt/miniconda/base/lib/python3.9/site-packages/pycounts'
├── __init__.py
├── __pycache__
├── plotting.py
└── pycounts.py
```

```
/opt/miniconda/base/lib/python3.9/site-packages/pycounts-0.1.0.dist-info
├── INSTALLER
├── LICENSE
├── METADATA
├── RECORD
├── REQUESTED
└── WHEEL
```

So the question is, how do we generate the *`{package}`* and *`{package}-{version}.dist-info`* for our package? There are two options:

1. Create an archive of all our package source code, metadata, and instructions on how to build it so it can be installed, and then share that archive with users. This is called a source distribution or sdist. A user would then download the archive, unpack it, and use the included build instructions to turn the source into *`{package}`* and *`{package}-{version}.dist-info`* folders. These can then be copied to their *`site-packages`* folder and used in a Python program. We'll talk more about what exactly we mean by "building" a package from source in **{numref}`04:Building-sdists-and-wheels`**.
2. Build the *`{package}`* and *`{package}-{version}.dist-info`* folders on our own machine, compress them into a single file, and share them with users. This single file is called a wheel. A user just needs to download the wheel the contents to the *`site-packages`* folder, no building required.

Distributing your package as a wheel (option 2) certainly seems preferable; everything has already been done on the developer's side and the user just needs to download the distribution and copy it to the appropriate location on their computer. This is why wheels are the preferred distribution format for Python packages. In fact, when you run `pip install`, it will always prioritize installing from a wheel (if it exists).

At this point you might be wondering why we bother with sdists at all. The reason is that wheels aren't always available to users. The main reason for this is that some Python packages contain "extensions" written in other languages, such as C/C++, because they offer functionality and performance enhancements. While Python is typically referred to as an interpreted language (i.e., your Python code is translated to machine code as it is executed), languages such as C/C++ require compilation by a compiler program before they can be used (i.e., your code must be translated into "machine code" *before* it can be executed). This compilation is platform-specific. Thus, if a developer wanted to provide wheels of a package, they would have to generate one for each platform they wanted to support. For this reason, sdists are usually provided with wheels; if a wheel isn't available for a user's particular platform, they will still be able to (try to) build the package from the sdist.

As an example, the popular `numpy` package contains extensions written in C, so its wheels are platform-specific. Wheels have a specific naming convention (described in [PEP 427](https://www.python.org/dev/peps/pep-0427/)) which includes the name of the platform they support; if you look at `numpy`'s [distributions on PyPi](https://pypi.org/project/numpy/#files), you'll see wheels for common platforms (variations of MacOS, Linux, Windows, etc.), as well as an sdist at the bottom of the list.

Wheels specific to a platform are known as "platform wheels". However, the vast majority of Python packages use pure Python code (i.e., they don't include extensions written in other languages that require platform-specific compilation), and so don't need to worry about generating platform wheels. Instead, pure-Python packages will be built as either:

1. Universal wheels: can be installed on any platform using either Python 2 or Python 3; 
2. Pure Python wheels: can be installed on any platform but only support one version of Python (e.g., Python 2 or Python 3).

Now we know a bit more about how packages are installed. But we have yet to talk about how wheels and our *`{package}`* and *`{package}-{version}.dist-info`* folders are actually built from a package's source files. That's coming up in the next section.

### Building sdists and wheels

The term "build" refers to one of two things:
- Building the sdist from a package's source files;
- Buidling a wheel from the sdist.

Regardless of the situation, a tool is required to do the building. That's where packaging tools like `poetry`, `flit` or `setuptools` comes in. These tools provide the code required to build sdists and wheels. 

Recall the *`pyproject.toml`* file `poetry` uses. One table in that file we have yet to talk about is the build system:

```toml
...other file content hidden...

[build-system]
requires = ["poetry-core>=1.0.0"]
build-backend = "poetry.core.masonry.api"
```

This section specifies the tools required to build the sdist and wheel. Moreover, it specifies to users what build tool they should use if they are building the package from an sdist on their own machine. The mechanics are a little beyond the scope of this book, but [PEP 517] and [PEP 518] are to thank for this. What happens if a users has to isntall from an sdist, basically this:

1. create a temporary folder
2. create an isolated (from the third-party site-packages) python 1. environment python -m virtualenv our_build_env, let’s refer to this 1. python executable as python_isolated
3. install the build dependencies
4. generate a wheel we can install via python_isolated setup.py bdist_wheel
5. extract wheel to site packages of python.

pip install --no-binary pycounts --use-pep517 pycounts -v

### Packaging tools

<!-- #region -->
- the main packaging tools are `poetry`, `flit`, and `setuptools`. 
- poetry and flit are similar - they offer an intuitive api for building and dsitrubting packages and are configured entirely from a `*pyproject.toml`* file. we use poetry because of its ability to resolve dependencies as they're added to your package, which flit can;t do.
- A caveat on the use of `poetry` and `flit` is that, at the time of writing, they only support pure Python projects. This will be completely fine for the vast majority of prospective packagers. However, for those looking to build more advanced packages that include non-Python code, we recommend reading [this documentation](https://packaging.python.org/guides/packaging-binary-extensions/#cross-platform-wheel-generation-with-scikit-build) from the Python Packaging Authority.
- setuptools does offer this


The focus of this book is on workflows and tools that make packaging accessible and efficient. `poetry` is one of those tools. It abstract most of the lower-level details away from the packager and provides an easy-to-use CLI to develop, build, and publish a package - so developers can focus on writing code and not worry about the nuances of building and sharing it within the constraints of the Python ecosystem.

Another tool worth mentioning here is `flit`. `flit` is a slightly stripped down version of `poetry` in that it is a Python package that provides a simple tool to put Python packages and modules on PyPI. It is similarly configured with the *`pyproject.toml`* file and provides CLI commands such as `build`, `install`, and `publish`. At the time of writing, the main difference between `flit` and `poetry` is that `flit` doesn’t help you manage or resolve dependencies. This is a useful feature, especially for beginner and intermediate packagers, which is why we typically choose to use `poetry` for our package development. `poetry` also implicitly supports the use of virtual environments but this is a feature we haven't used in this book, in favor of using `conda`. This is mostly personal choice but `conda` can be used with `flit` for example, illustrating one of the reasons we chose to use it - it's universal.

A caveat on the use of `poetry` and `flit` is that, at the time of writing, they only support pure Python projects. This will be completely fine for the vast majority of prospective packagers. However, for those looking to build more advanced packages that include non-Python code, we recommend reading [this documentation](https://packaging.python.org/guides/packaging-binary-extensions/#cross-platform-wheel-generation-with-scikit-build) from the Python Packaging Authority.
<!-- #endregion -->

## Version control

In **{numref}`04:Including-data-in-a-package`** we made an important change to our `pycounts` package by adding a new `datasets` module and some example data. We will make a new release of our package in **Chapter 7: [Releasing and versioning]** that incorporates this change. So, if you're following along building the `pycounts` package yourself and using version control, commit these changes to your local and remote repositories using the commands below. If you're not building the `pycounts` package or not using version control, you can skip to the next chapter.

```{prompt} bash \$ auto
$ git add src/pycounts/datasets.py src/pycounts/data
$ git commit -m "feat: added example data and datasets module"
$ git push
```

## Package repositories

Before talking about versioning in more detail, it's useful to briefly talk about package repositories. If you're planning on sharing your software with users other than your future self, you first need to decide where to release it to.

The Python Package Index ([PyPI](https://pypi.org/)) is the official software repository for Python. If you're interested in sharing your work publicly, this is probably where you'll be releasing your package. In **Chapter 3: [How to package a Python]** we released our `partypy` package to PyPI. While we focus on releasing packages to PyPI in this book, it is not the only option. Another popular software repository for Python (and other languages) software is that hosted by [Anaconda](https://www.anaconda.com/) and accessible with the `conda` (which we installed back in **Chapter 2: [System setup]**). We won't go into the details of the differences between these two popular repositories here, but if you're interested to read more, we recommend [this article](https://www.anaconda.com/blog/understanding-conda-and-pip). Creating packages for Anaconda requires a little more work than for PyPI but Anaconda provides a [helpful tutorial](https://docs.conda.io/projects/conda-build/en/latest/user-guide/tutorials/build-pkgs-skeleton.html) on the workflow.

In some cases, you may want to release your package to a private repository (for example, for internal use by your company only). There are many private repository options for Python packages. Companies like [Anaconda](https://docs.anaconda.com/), [PyDist](https://pydist.com/) and [GemFury](https://gemfury.com/) are all examples that offer (typically paid) private Python package repository hosting. You can also set up your own server on a dedicated machine or cloud service like AWS - read more [here](https://medium.com/swlh/how-to-install-a-private-pypi-server-on-aws-76993e45c610).

Finally, you can also choose to simply host your package on GitHub (or equivalent), and forego releasing to a dedicated software repository like PyPI. In some cases, it is possible for users to `pip install` directly from a GitHub repository (read [this excellent article](https://adamj.eu/tech/2019/03/11/pip-install-from-a-git-repository/) to learn more). For example, to install the `partypy` package directly from GitHub:

```{prompt} bash \$ auto
$ python -m pip install git+https://github.com/TomasBeuzen/partypy.git
```

```{attention language="attention"}
We don't recommend GitHub for sharing Python packages to a wide audience as the install workflow can often be problematic, the vast majority of Python users do not install packages from GitHub, and dedicated software repositories like PyPI provide better discoverability, ease of installation, and a stamp of authenticity.
```
